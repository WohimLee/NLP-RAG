# RAG
## 1 大规模语言模型的现状及挑战
在自然语言处理领域, 大型语言模型（LLM）如GPT-3、BERT等已经取得了显著的进展, 它们能够生成连贯、自然的文本, 回答问题, 并执行其他复杂的语言任务。然而, 这些模型存在一些固有的局限性, 如 “模型幻觉问题”、“时效性问题”和“数据安全问题”。

大模型的幻觉指的是模型或产生大量不准确或误导性的输出，这种幻觉会导致大模型输出似是而非但实际不正确的答案，或者给出与上下文并不相关的输出。这种幻觉来的本质是由于大语言模型本身缺乏对于现实世界的感知能力，其训练数据可能存在偏见，不完整，错误虚假信息，训练中可能存在的过拟合和量化误差，以及Prompt上下文缺失等情况。OpenAI也提到：ChatGPT具有巨大的使用现有文档的能力，但它没有辨别真假的能力。它不是为此而建的。在某些关键任务中，幻觉的确可能带来严重的后果和误导。

当然，幻觉的存在不意味着大模型就无法在生产环境中落地。治理幻觉的方式有很多，包括在训练时提供更高质量的数据，对模型进行Finetune补充领域内知识，在RLHF给予Reward Model关于数据真实性更高的倾向性，通过Prompt引导大模型避免对缺乏信息的问题进行生成，以及本文所提到Retrieval Augment Generation，基于向量数据库的召回式生成。合理利用幻觉，可以充分发挥大模型的推理能力和创造能力，解决更加发散性的问题。

为了克服这些限制, 检索增强生成（RAG）技术应运而生。

- 多功能性和智能化：LLMs改变了我们与信息的互动方式
- 存在的问题：误导性的“幻觉”、信息过时、缺乏专业深度、推理能力欠缺等


## 2 RAG (检索增强生成技术)
Retrieval Augment Generation有两个重要的组成部分，`预训练大模型`和`领域知识库`。大模型时代，AI的应用发生了新的范式变化，从过往的`预训练+Finetune`的模式转换为了`预训练+Prompt`，这大大简化了对于不同任务训练模型的工作量，降低了AI的开发和使用门槛，也把搜索结合生成成为了可能。

在RAG架构中，预训练LLM往往有以下几个特点：

- 基于Transformer架构，准确捕获句子之间的相关性
- 基于预测上下文的Token任务进行预训练，同时结合RLHF技术使得生成结果更加符合人的喜好
- 规模较大，往往需要百亿甚至千亿级别参数，泛化能力较强

另一方面，对领域知识的补充往往依赖于特定的数据存储，如向量数据库，搜索引擎或者图数据库。这其中，向量数据库因为具备对高维Embedding的检索能力，跟大模型的结合最为简单，效果也比较出色，目前是RAG中最为常用的数据存储方式。


<div align=center>
    <image src="imgs/RAG.png" width=800>
</div>
