## 1 大规模语言模型的现状及挑战
在自然语言处理领域, 大型语言模型（LLM）如GPT-3、BERT等已经取得了显著的进展, 它们能够生成连贯、自然的文本, 回答问题, 并执行其他复杂的语言任务。然而, 这些模型存在一些固有的局限性, 如 “模型幻觉问题”、“时效性问题”和“数据安全问题”。为了克服这些限制, 检索增强生成（RAG）技术应运而生。

- 多功能性和智能化：LLMs改变了我们与信息的互动方式
- 存在的问题：误导性的“幻觉”、信息过时、缺乏专业深度、推理能力欠缺等
## 2 检索增强生成技术（RAG）的出现
- 背景：数据需要不断更新，内容必须透明可追溯，控制成本和保护数据隐私
- 基础RAG架构：简单快速搭建，但在生产环境中还需优化
- 优化路径：增加召回管道和反馈机制，以提高文档召回率和系统鲁棒性


<div align=center>
    <image src="imgs/RAG.png" width=800>
</div>

## 3 各环节的优化方法
### 3.1 文本数据预处理
- 实体解析：消除歧义，实现一致引用。
- 文档划分：合理划分不同主题的文档。
- 数据增强：增加同义词、释义、翻译等多样性。
- 处理特殊数据：更新或失效过时的文档。
- 增加元数据：丰富知识库内容。
### 3.2 文本分块
- 方法：句分割、递归分割、语义分割、特殊结构分割。
- 块大小选择：根据文档类型和用户查询长度调整，常用128大小作为起点。
### 3.3 嵌入
- 动态嵌入：处理一词多义情况。
- 微调嵌入：垂直领域词汇理解更好。
- 混合嵌入：用户问题和知识库文本使用不同嵌入模型。
### 3.4 查询优化
- 查询重写：改写用户的问题。
- 后退提示：提出高层次概念或原则的抽象问题。
- Follow Up Questions：生成独立问题，确保对话上下文一致。
- HyDE：生成假设答案，辅助检索。
- 多问题查询：从不同角度生成多个新问题。
### 3.5 检索
- 上下文压缩：过滤不相关信息。
- 句子窗口搜索：增加上下文理解。
- 父文档搜索：按层级结构匹配文档。
- 自动合并：复杂的多层结构匹配。
- 混合检索：结合多种检索方法。
- 路由机制：选择最合适的索引。
- 使用Agent：动态决定检索方法。
### 3.6 检索后处理
- 重排序（Rerank）：确保最相关的文档排在前面。
## 4 生成阶段的优化
- 多轮对话：支持连续对话。
- 增加追问机制：引导用户明确问题。
- prompt优化：明确回答基于搜索结果。
- 用户反馈循环：根据用户反馈更新数据库。

